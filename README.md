# n8n Nodes Scraper & Explorer

Eine umfassende Sammlung von Tools zum Scrapen, Speichern und Durchsuchen aller n8n Node-Types (Official, Community & Custom).

## ğŸ¯ Features

- **Intelligente Suche** - Synonym-basierte Suche mit Relevanz-Ranking
- **Multi-Source Scraping** - Holt Nodes aus n8n Docs, GitHub, npm Registry und n8n API
- **SQLite Datenbank** - Zentrale Speicherung aller Node-Informationen
- **Streamlit Web-App** - Interaktive UI zum Durchsuchen aller Nodes
- **Automatische camelCase Korrektur** - Stellt sicher, dass Node-Namen workflow-kompatibel sind

## ğŸ“ Projekt-Struktur

```
n8nScraper/
â”œâ”€â”€ scripts/                    # Scraping Scripts
â”‚   â”œâ”€â”€ scraper.py             # Jina AI Documentation Scraper
â”‚   â”œâ”€â”€ github_node_scraper.py # GitHub Repository Scraper
â”‚   â”œâ”€â”€ n8n_api_scraper.py     # n8n API Scraper
â”‚   â”œâ”€â”€ search_community_nodes.py # npm Registry Community Nodes
â”‚   â””â”€â”€ populate_all_nodes.py  # Populate DB with complete node list
â”‚
â”œâ”€â”€ utils/                      # Utility Scripts
â”‚   â”œâ”€â”€ check_casing.py        # Verify node name casing
â”‚   â”œâ”€â”€ check_community_stats.py # Community nodes statistics
â”‚   â”œâ”€â”€ show_stats.py          # Database statistics
â”‚   â”œâ”€â”€ export_nodes_to_md.py  # Export to Markdown
â”‚   â””â”€â”€ fix_node_casing.py     # Fix lowercase to camelCase
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ README.md              # This file
â”‚   â”œâ”€â”€ README_APP.md          # Streamlit App Documentation
â”‚   â””â”€â”€ INTELLIGENT_SEARCH.md  # Search algorithm docs
â”‚
â”œâ”€â”€ data/                       # Data files
â”‚   â””â”€â”€ n8n_docs.db           # SQLite database (auto-generated)
â”‚
â”œâ”€â”€ output/                     # Generated output
â”‚   â””â”€â”€ n8n_node_types.md     # Markdown export of all nodes
â”‚
â”œâ”€â”€ n8n_nodes_app.py           # Main Streamlit Application
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ .gitignore                # Git ignore rules
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone Repository
git clone https://github.com/yourusername/n8nScraper.git
cd n8nScraper

# Install Dependencies
pip install -r requirements.txt
```

### 2. Daten sammeln (Optional)

Die Datenbank ist bereits vorausgefÃ¼llt. Falls du sie neu erstellen mÃ¶chtest:

```bash
# Offizielle Nodes (443 Nodes)
python scripts/populate_all_nodes.py

# GitHub Nodes (bis zu 307 Nodes, API-limitiert)
python scripts/github_node_scraper.py

# n8n API Nodes (aus deinen Workflows)
python scripts/n8n_api_scraper.py

# Community Nodes von npm (~20.000+ Nodes)
python scripts/search_community_nodes.py

# camelCase Korrektur anwenden
python utils/fix_node_casing.py
```

### 3. Streamlit App starten

```bash
streamlit run n8n_nodes_app.py
```

Die App Ã¶ffnet sich automatisch unter `http://localhost:8501`

## ğŸ“Š Datenquellen

| Quelle | Nodes | Beschreibung |
|--------|-------|--------------|
| **populate_all_nodes.py** | 443 | VollstÃ¤ndige Liste offizieller n8n Nodes |
| **github_node_scraper.py** | ~66 | Direkt aus GitHub Repository .node.json Files |
| **n8n_api_scraper.py** | 31 | Extrahiert aus eigenen n8n Workflows |
| **search_community_nodes.py** | ~20.000+ | Community Nodes von npm Registry |

**Gesamt:** ~21.000+ Nodes in der Datenbank

## ğŸ” Intelligente Suche

Die Streamlit App verwendet eine intelligente Suche mit:

- **Synonym-Erweiterung** - "email" findet automatisch Gmail, Outlook, SMTP, etc.
- **Relevanz-Ranking** - Beste Matches zuerst
- **Kategorie-Filter** - Nach App, Trigger, Core, LangChain, Community
- **Quick Search Buttons** - HÃ¤ufige Suchen mit einem Klick

### Beispiel-Suchen:

```
email     â†’ Gmail, Outlook, SMTP, IMAP, Mailchimp, SendGrid...
database  â†’ Postgres, MySQL, MongoDB, Redis, SQL...
ai        â†’ OpenAI, Anthropic, Claude, GPT, Gemini, LangChain...
chat      â†’ Slack, Teams, Discord, Telegram, WhatsApp...
cloud     â†’ AWS, Azure, Google Cloud, S3, Drive, Dropbox...
```

Siehe [INTELLIGENT_SEARCH.md](docs/INTELLIGENT_SEARCH.md) fÃ¼r Details.

## ğŸ—ƒï¸ Datenbank-Schema

```sql
-- Offizielle Nodes aus Dokumentation
CREATE TABLE node_types_api (
    node_type TEXT UNIQUE NOT NULL,      -- z.B. n8n-nodes-base.gmail
    display_name TEXT,                   -- z.B. Gmail
    description TEXT,
    category TEXT,                       -- App, Trigger, Core, LangChain
    version INTEGER,
    icon TEXT,
    scraped_at TIMESTAMP
);

-- Nodes aus GitHub Repository
CREATE TABLE node_types_github (
    node_type TEXT UNIQUE NOT NULL,
    display_name TEXT,
    description TEXT,
    version INTEGER,
    folder_path TEXT,
    scraped_at TIMESTAMP
);

-- Community Nodes von npm
CREATE TABLE community_nodes (
    package_name TEXT UNIQUE NOT NULL,  -- z.B. @apify/n8n-nodes-apify
    node_types TEXT,
    description TEXT,
    version TEXT,
    author TEXT,
    repository TEXT,
    downloads INTEGER,
    scraped_at TIMESTAMP
);

-- Scraping Queue/Log
CREATE TABLE pages (
    url TEXT UNIQUE NOT NULL,
    title TEXT,
    node_type TEXT,
    markdown_content TEXT,
    scraped_at TIMESTAMP
);
```

## ğŸ› ï¸ Utility Scripts

### Statistiken anzeigen

```bash
python utils/show_stats.py
```

Zeigt Anzahl der Nodes pro Kategorie.

### Community Nodes Status

```bash
python utils/check_community_stats.py
```

Zeigt Fortschritt des Community Node Scrapings.

### Casing Ã¼berprÃ¼fen

```bash
python utils/check_casing.py
```

Vergleicht GroÃŸ-/Kleinschreibung zwischen GitHub und API Nodes.

### Export zu Markdown

```bash
python utils/export_nodes_to_md.py
```

Exportiert alle Nodes in eine Ã¼bersichtliche Markdown-Datei.

## âš™ï¸ Konfiguration

### n8n API Key (fÃ¼r n8n_api_scraper.py)

Setze deine n8n API Credentials in `scripts/n8n_api_scraper.py`:

```python
API_URL = "https://your-n8n-instance.com"
API_KEY = "your-api-key-here"
```

### Jina AI Key (fÃ¼r scraper.py - optional)

FÃ¼r Dokumentations-Scraping via Jina AI Reader:

```python
JINA_API_KEY = "your-jina-api-key"
```

## ğŸ“ˆ Performance

- **Suche:** <100ms fÃ¼r vollstÃ¤ndige Suche Ã¼ber 20.000+ Nodes
- **Caching:** 60 Sekunden TTL fÃ¼r Datenbankabfragen
- **Scraping Rate Limits:**
  - GitHub API: 60 req/h (unauth) / 5000 req/h (auth)
  - npm Registry: keine bekannten Limits
  - n8n API: abhÃ¤ngig von deiner Instanz

## ğŸ”§ Entwicklung

### Neue Synonyme hinzufÃ¼gen

Bearbeite `n8n_nodes_app.py`:

```python
def expand_search_terms(search_term):
    synonyms = {
        'dein_begriff': ['synonym1', 'synonym2', 'synonym3'],
        # ... weitere
    }
```

### Neue Datenquelle hinzufÃ¼gen

1. Erstelle neues Script in `scripts/`
2. Verbinde mit `n8n_docs.db`
3. FÃ¼ge Daten in entsprechende Tabelle ein
4. Aktualisiere `n8n_nodes_app.py` um neue Quelle zu laden

## ğŸ“ Wichtige Hinweise

### camelCase ist wichtig!

n8n Workflow JSON Files benÃ¶tigen **exakte camelCase** Node-Namen:

```json
{
  "type": "n8n-nodes-base.microsoftOutlook"  // âœ… Richtig
}
```

**NICHT:**
```json
{
  "type": "n8n-nodes-base.microsoftoutlook"  // âŒ Falsch - funktioniert nicht!
}
```

Das Script `utils/fix_node_casing.py` korrigiert automatisch alle lowercase Namen zu camelCase.

## ğŸ¤ Contributing

Contributions sind willkommen! Besonders:

- Neue Synonyme fÃ¼r die intelligente Suche
- Weitere Datenquellen
- Verbesserungen der Streamlit App
- Dokumentation

## ğŸ“„ Lizenz

MIT License

## ğŸ”— Links

- [n8n Documentation](https://docs.n8n.io/)
- [n8n GitHub](https://github.com/n8n-io/n8n)
- [n8n Community](https://community.n8n.io/)
- [npm Registry](https://www.npmjs.com/search?q=n8n-nodes)

## ğŸ‘¨â€ğŸ’» Autor

Erstellt mit Claude Code

---

**Status:**
- âœ… 443 Official Nodes
- âœ… 66 GitHub Nodes
- âœ… 20.000+ Community Nodes
- âœ… Intelligente Suche
- âœ… Streamlit Web-App
